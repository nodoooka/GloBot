import os
import asyncio
import logging
from pathlib import Path
from openai import AsyncOpenAI
import sys
import re
import html

sys.path.append(str(Path(__file__).resolve().parent.parent))
from common.config_loader import settings, MASTER_LLM_API_KEY, WORKER_GLM_API_KEY
from Bot_Media.rag_manager import RAGManager

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

WORKER_BASE_URL = os.getenv("WORKER_BASE_URL", "https://open.bigmodel.cn/api/paas/v4/")
WORKER_MODEL = os.getenv("WORKER_MODEL", "glm-4-flash")

MASTER_BASE_URL = os.getenv("MASTER_BASE_URL", "https://api.deepseek.com") 
MASTER_MODEL = os.getenv("MASTER_MODEL", "deepseek-chat")

worker_client = AsyncOpenAI(api_key=WORKER_GLM_API_KEY, base_url=WORKER_BASE_URL) if WORKER_GLM_API_KEY else None
master_client = AsyncOpenAI(api_key=MASTER_LLM_API_KEY, base_url=MASTER_BASE_URL) if MASTER_LLM_API_KEY else None

rag = RAGManager()

# ==========================================
# ğŸš€ å•å¥ç¿»è¯‘ï¼ˆä¿ç•™ç»™æ¨æ–‡å¤„ç†ä½¿ç”¨ï¼‰
# ==========================================
async def translate_text(jp_text: str, is_subtitle: bool = False) -> str:
    if not jp_text.strip(): return ""
    
    # ğŸ§¹ æ¸…æ´—æ¨ç‰¹åº•å±‚çš„ HTML è½¬ä¹‰å­—ç¬¦ (å¦‚å°† &lt; è¿˜åŸä¸º < )ï¼Œé˜²æ­¢å¤§æ¨¡å‹æŠ½é£
    clean_jp_text = html.unescape(jp_text)
    
    # ğŸ·ï¸ æ ¸å¿ƒä¿®å¤ï¼šç”¨æ­£åˆ™æå‰å°†æ¨ç‰¹å•äº•å·æ ‡ç­¾ #tag è½¬æ¢ä¸º Bç«™åŒäº•å· #tag#
    # è¿™æ ·ä¸ä»…é€‚é…äº† Bç«™æ ¼å¼ï¼Œè¿˜èƒ½æ‰“æ–­ Markdown çš„æ ‡é¢˜è¯­æ³•ï¼Œé˜²æ­¢å¤§æ¨¡å‹è·³è¿‡è¯¥è¡Œï¼
    clean_jp_text = re.sub(r'#(\w+)', r'#\1#', clean_jp_text)
    
    rag_context = rag.build_context_prompt(clean_jp_text)
    
    # å¼ºåˆ¶æµ‹è¯•ï¼šæ— è§†é•¿çŸ­ï¼Œæ‰€æœ‰æ¨æ–‡å…¨éƒ¨äº¤ç»™ Master æ¨¡å‹ (DeepSeek/GPT ç­‰) å¤„ç†ï¼
    active_client, active_model = master_client, MASTER_MODEL

    # ğŸ§  æ ¸å¿ƒé‡æ„ï¼šä» config.yaml ä¸­åŠ¨æ€è¯»å–å¯¹åº”çš„æç¤ºè¯
    system_prompt = settings.prompts.video_translation_prompt if is_subtitle else settings.prompts.tweet_translation_prompt
    
    try:
        # 1. ç»„è£…è¦å‘é€çš„å®Œæ•´æ¶ˆæ¯ä½“ï¼ˆåŠ å…¥ç‰©ç†è¾¹ç•Œç¬¦éš”ç¦»ï¼‰
        messages_payload = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"è¯·ç¿»è¯‘ä»¥ä¸‹æ¨æ–‡ï¼š\n<text>\n{clean_jp_text}\n</text>\n\n{rag_context}"}
        ]
        
        # 2. ğŸš¦ å¢åŠ é€šä¿¡æ¢é’ˆï¼šæ‰“å°å³å°†å‘ç»™å¤§æ¨¡å‹çš„å®Œæ•´ JSON
        import json
        logger.info(f"   -> [å¤§æ¨¡å‹é€šä¿¡æ¢é’ˆ] å®Œæ•´ Request Payload:\n{json.dumps(messages_payload, ensure_ascii=False, indent=2)}")
        
        # 3. å‘é€è¯·æ±‚
        response = await active_client.chat.completions.create(
            model=active_model,
            messages=messages_payload,
            temperature=0.3, max_tokens=500
        )
        
        result = response.choices[0].message.content.strip()
        
        # 4. ğŸš¦ å¢åŠ å“åº”æ¢é’ˆï¼šæ‰“å°å¤§æ¨¡å‹çœŸå®è¿”å›çš„ Raw Data
        logger.info(f"   -> [å¤§æ¨¡å‹é€šä¿¡æ¢é’ˆ] Raw Response: '{result}'")
        
        if not result:
            logger.warning(f"âš ï¸ å¤§æ¨¡å‹å‚²å¨‡äº†ï¼Œè¿”å›äº†ç©ºå­—ç¬¦ä¸²ï¼è§¦å‘é˜²çˆ†å…œåº•ï¼Œç›´æ¥ä½¿ç”¨æ¸…æ´—åçš„åŸæ–‡ã€‚")
            return clean_jp_text
            
        return result
    except Exception as e:
        logger.error(f"âŒ ç¿»è¯‘å¤±è´¥: {e}")
        # å¦‚æœæ–­ç½‘æˆ– API æ¬ è´¹ï¼Œä¾ç„¶ç”¨åŸæ–‡å…œåº•
        return html.unescape(jp_text)

# ==========================================
# ğŸš€ å·¥ä¸šçº§æ‰¹å¤„ç†ï¼šæ•´ç‰‡è§†é¢‘å°è¯ä¸€æ¬¡æ€§ç¿»è¯‘
# ==========================================
async def translate_batch(segments: list, ocr_results: list) -> list:
    """å°†æ•´æ®µè§†é¢‘å­—å¹•æ‰“åŒ…ï¼Œä¸€æ¬¡æ€§äº¤ç”± Master æ¨¡å‹è¿›è¡Œä¸Šä¸‹æ–‡æ„ŸçŸ¥ç¿»è¯‘"""
    if not segments:
        return []

    # 1. ç»„è£…å¸¦æœ‰ OCR è§†è§‰ä¸Šä¸‹æ–‡çš„å¸¦åºå·å‰§æœ¬
    input_lines = []
    full_text_for_rag = "" # ç”¨äºä¸€æ¬¡æ€§æå–æ‰€æœ‰çŸ¥è¯†åº“Buff
    
    for i, seg in enumerate(segments):
        start, end, text = seg['start'], seg['end'], seg['text'].strip()
        full_text_for_rag += text + " "
        
        # åŒ¹é…è¯¥æ—¶é—´æ®µçš„èŠ±å­—
        hits = [o['text'] for o in ocr_results if not (o['end_time'] < start or o['start_time'] > end)]
        ocr_hint = f" [ç”»é¢èŠ±å­—: {' | '.join(hits)}]" if hits else ""
        
        input_lines.append(f"{i+1}. {text}{ocr_hint}")

    script_text = "\n".join(input_lines)
    rag_context = rag.build_context_prompt(full_text_for_rag)
    
    # æ•´ç‰‡ç¿»è¯‘å±äºé‡åº¦æ¨ç†ä»»åŠ¡ï¼Œå¼ºåˆ¶è·¯ç”±ç»™ Master èŠ‚ç‚¹ï¼ˆæˆ–é™çº§ï¼‰
    active_client = master_client or worker_client
    active_model = MASTER_MODEL if master_client else WORKER_MODEL
    
    if not active_client:
        return [seg['text'] for seg in segments]

    logger.info(f"ğŸ§  [æ™ºèƒ½è·¯ç”±] æ­£åœ¨å°† {len(segments)} å¥å°æœ¬æ‰“åŒ…ï¼Œç§»äº¤ã€å¤§å¸ˆèŠ‚ç‚¹ {active_model}ã€‘...")

    # ğŸ§  æ ¸å¿ƒé‡æ„ï¼šç›´æ¥è¯»å–è§†é¢‘ä¸“å±çš„æç¤ºè¯
    system_prompt = settings.prompts.video_translation_prompt

    try:
        response = await active_client.chat.completions.create(
            model=active_model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"è¯·ç¿»è¯‘ä»¥ä¸‹å°æœ¬ï¼š\n<text>\n{script_text}\n</text>\n\n{rag_context}"}
            ],
            temperature=0.2, # è¾ƒä½çš„æ¸©åº¦ç¡®ä¿ç»“æ„ç¨³å®š
            max_tokens=2000
        )
        
        output_text = response.choices[0].message.content.strip()
        
        # 2. è§£æå¤§æ¨¡å‹è¿”å›çš„å¸¦åºå·æ–‡æœ¬
        translated_lines = []
        # ä½¿ç”¨æ­£åˆ™åŒ¹é…åºå·ï¼Œç¡®ä¿é²æ£’æ€§
        parsed_lines = re.split(r'\n\s*\d+\.\s*', '\n' + output_text)[1:] 
        
        # å¦‚æœæ¨¡å‹æå…¶å¬è¯æ²¡å‡ºå²”å­ï¼Œé•¿åº¦åº”è¯¥å’Œ segments ä¸€è‡´
        for i in range(len(segments)):
            if i < len(parsed_lines) and parsed_lines[i].strip():
                translated_lines.append(parsed_lines[i].strip())
            else:
                translated_lines.append(segments[i]['text']) # å…œåº•ï¼šå¦‚æœå°‘ç¿»äº†å°±ç”¨æ—¥æ–‡åŸæ–‡
                
        return translated_lines
        
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡ç¿»è¯‘è¯·æ±‚å´©æºƒ: {e}")
        return [seg['text'] for seg in segments] # å½»åº•æ–­ç½‘çš„å…œåº•æ–¹æ¡ˆ