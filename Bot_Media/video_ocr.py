import cv2
import time
import logging
from pathlib import Path
import Foundation
import Vision
import sys
import asyncio

# å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ç³»ç»Ÿè·¯å¾„
sys.path.append(str(Path(__file__).resolve().parent.parent))
from common.config_loader import settings

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

class MacVisionOCR:
    def __init__(self):
        logger.info("âš¡ æ­£åœ¨å”¤é†’ Mac Apple Neural Engine (Vision Framework) ...")
        self.request = Vision.VNRecognizeTextRequest.alloc().init()
        # âš ï¸ æå…¶å…³é”®ï¼šå¼ºåˆ¶å‘Šè¯‰ NPU æˆ‘ä»¬è¦æŠ“å–æ—¥è¯­å’Œè‹±è¯­ï¼
        self.request.setRecognitionLanguages_(["ja-JP", "en-US"])
        self.request.setUsesLanguageCorrection_(True)
        # å¯ç”¨é«˜ç²¾åº¦æ¨¡å¼ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æŠŠä»»åŠ¡æ´¾å‘ç»™ M3 Pro çš„ NPU
        self.request.setRecognitionLevel_(Vision.VNRequestTextRecognitionLevelAccurate)

    def extract_text_from_frame(self, frame) -> list:
        """æ¡¥æ¥ OpenCV ä¸ Mac åº•å±‚ APIï¼Œè¿›è¡Œæ¯«ç§’çº§æ–‡å­—æå–"""
        # å°† C++ å±‚çš„ OpenCV å›¾åƒï¼ˆNumpyï¼‰æ— æŸè½¬å…¥ Objective-C å†…å­˜æ± 
        _, buffer = cv2.imencode('.jpg', frame)
        ns_data = Foundation.NSData.dataWithBytes_length_(buffer.tobytes(), len(buffer.tobytes()))
        
        handler = Vision.VNImageRequestHandler.alloc().initWithData_options_(ns_data, None)
        success, _ = handler.performRequests_error_([self.request], None)
        
        results = []
        if success:
            for observation in self.request.results():
                text = observation.topCandidates_(1)[0].string()
                bbox = observation.boundingBox()
                # è½¬æ¢ Vision çš„å·¦ä¸‹è§’åæ ‡ç³»ä¸º [x_min, y_min, x_max, y_max] æ¯”ä¾‹åæ ‡
                x_min, y_min = bbox.origin.x, bbox.origin.y
                x_max, y_max = x_min + bbox.size.width, y_min + bbox.size.height
                
                results.append({
                    "text": text,
                    "box": [x_min, y_min, x_max, y_max],
                    "height": bbox.size.height
                })
        return results

def calculate_iou(box1, box2):
    """è®¡ç®—äº¤å¹¶æ¯” (IOU) - ç”¨äºåˆ¤æ–­æ˜¯ä¸æ˜¯åŒä¸€å¥èŠ±å­—ä¸€ç›´åœåœ¨å±å¹•ä¸Š"""
    x_left = max(box1[0], box2[0])
    y_top = max(box1[1], box2[1])
    x_right = min(box1[2], box2[2])
    y_bottom = min(box1[3], box2[3])

    if x_right < x_left or y_bottom < y_top:
        return 0.0

    intersection = (x_right - x_left) * (y_bottom - y_top)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    return intersection / (area1 + area2 - intersection)

# ==========================================
# ğŸš€ è§†é¢‘èŠ±å­—æ—¶ç©ºæå–ä¸»è½´
# ==========================================
async def extract_video_text(video_path: Path) -> list:
    logger.info(f"ğŸ‘ï¸ [è§†è§‰å¼•æ“å¯åŠ¨] å¼€å§‹æ‰«æè§†é¢‘å¤§å­—æŠ¥: {video_path.name}")
    start_time = time.time()
    
    ocr_engine = MacVisionOCR()
    cap = cv2.VideoCapture(str(video_path))
    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps <= 0:
        fps = 30.0

    # æ¯ç§’æŠ½ 4 å¸§ (è¶³å¤Ÿæ•æ‰åœ°ä¸‹å¶åƒçš„å¿«é—ªå­—å¹•)
    frame_interval = int(fps / 4)
    
    min_height = settings.media_engine.ocr_min_height_ratio
    iou_thresh = settings.media_engine.ocr_iou_threshold

    active_texts = []
    final_texts = []
    
    frame_count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
            
        if frame_count % frame_interval == 0:
            current_sec = frame_count / fps
            raw_results = ocr_engine.extract_text_from_frame(frame)
            
            # 1. è¿‡æ»¤ï¼šä¸¢æ‰é«˜åº¦å°äº 3% çš„èƒŒæ™¯æ‚å­—ï¼ˆæ¯”å¦‚è¡£æœä¸Šçš„å°logoï¼‰
            valid_results = [r for r in raw_results if r['height'] >= min_height]
            
            # 2. æ—¶ç©ºèåˆï¼šæ£€æŸ¥å½“å‰å­—å¹•æ˜¯ä¸æ˜¯ä¸Šä¸€ç§’å°±åœ¨å±å¹•ä¸Šäº†
            new_active_texts = []
            for current_item in valid_results:
                matched = False
                for active_item in active_texts:
                    # åªè¦ä½ç½®é«˜åº¦é‡åˆ (IOU > 0.8) æˆ–è€…æ–‡å­—å®Œå…¨ä¸€æ ·ï¼Œæˆ‘ä»¬å°±è®¤ä¸ºæ˜¯åŒä¸€å¥å°è¯ï¼
                    if calculate_iou(current_item['box'], active_item['box']) > iou_thresh or current_item['text'] == active_item['text']:
                        active_item['end_time'] = current_sec # å»¶é•¿å­˜æ´»æ—¶é—´
                        active_item['box'] = current_item['box'] # æ›´æ–°æœ€æ–°ä½ç½®
                        new_active_texts.append(active_item)
                        matched = True
                        break
                
                # è¿™æ˜¯ä¸€ä¸ªå…¨æ–°çš„èŠ±å­—ï¼
                if not matched:
                    new_active_texts.append({
                        "text": current_item['text'],
                        "start_time": current_sec,
                        "end_time": current_sec + 0.5, # è‡³å°‘ç»™ 0.5 ç§’çš„å­˜æ´»æœŸ
                        "box": current_item['box']
                    })
            
            # 3. æŠŠå·²ç»æ¶ˆå¤±çš„èŠ±å­—ç»“ç®—å½’æ¡£
            for active_item in active_texts:
                if active_item not in new_active_texts:
                    final_texts.append(active_item)
                    
            active_texts = new_active_texts
            
        frame_count += 1

    cap.release()
    # ç»“ç®—æœ€åä¸€æ³¢è¿˜æ²¡æ¶ˆå¤±çš„å­—å¹•
    final_texts.extend(active_texts)
    
    cost_time = time.time() - start_time
    logger.info(f"âœ… [è§†è§‰æ‰«æå®Œæ¯•] è€—æ—¶ {cost_time:.2f} ç§’ï¼å…±æ•è· {len(final_texts)} å¥ç¡¬å­—å¹•ã€‚")
    
    # æŒ‰æ—¶é—´è½´æ’åºè¿”å›
    return sorted(final_texts, key=lambda x: x['start_time'])

# ==========================================
# ğŸ§ª æœ¬åœ°å•ç‚¹æµ‹è¯•
# ==========================================
if __name__ == "__main__":
    # âš ï¸ è¯·æŠŠè¿™é‡Œæ›¿æ¢ä¸ºä½ ç”µè„‘ä¸Šä¸€æ®µæœ‰â€œå¤§å·æ—¥æ–‡å­—å¹•â€çš„çŸ­è§†é¢‘ç»å¯¹è·¯å¾„ï¼
    test_video = Path("/Users/tgmesmer/GloBot/GloBot_Data/iLiFE/media/ilife_official/2025556349686583620_video.mp4")
    
    async def run_test():
        if not test_video.exists():
            print("âŒ æ‰¾ä¸åˆ°è§†é¢‘ï¼Œè¯·æ›¿æ¢æœ€åº•éƒ¨çš„ test_video è·¯å¾„ï¼")
            return
            
        results = await extract_video_text(test_video)
        
        print("\n" + "="*50)
        print("ğŸ¯ NPU æå–åˆ°çš„å±å¹•èŠ±å­—æ—¶é—´è½´ï¼š")
        print("="*50)
        for item in results:
            print(f"[{item['start_time']:05.2f}s -> {item['end_time']:05.2f}s] {item['text']}")
            
    asyncio.run(run_test())