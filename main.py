import os
import asyncio
import logging
import random
from pathlib import Path
from datetime import datetime

# ==========================================
# å¯¼å…¥æ‰€æœ‰ç»„ä»¶
# ==========================================
from common.config_loader import settings
from Bot_Crawler.twitter_scraper import fetch_timeline
from Bot_Crawler.tweet_parser import parse_timeline_json
from Bot_Media.llm_translator import translate_text
from Bot_Media.media_pipeline import dispatch_media
from Bot_Publisher.bili_uploader import smart_publish

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger("GloBot_Main")

DATA_DIR = Path(os.getenv("LOCAL_DATA_DIR", f"./GloBot_Data/{settings.targets.group_name}"))
RAW_DIR = DATA_DIR / "timeline_raw"

# ç”¨äºè®°å½•æ˜¯å¦æ˜¯é¡¹ç›®æœ‰å²ä»¥æ¥ç¬¬ä¸€æ¬¡æ‰§è¡Œ
FIRST_RUN_FLAG_FILE = DATA_DIR / ".first_run_completed"

async def process_pipeline(tweet: dict) -> bool:
    """å…¨é“¾è·¯å¤„ç†å•æ¡æ¨æ–‡ï¼ˆç¿»è¯‘ -> è§†é¢‘å‹åˆ¶ -> å‘å¸ƒï¼‰"""
    tweet_id = tweet['id']
    raw_text = tweet['text']
    media_files = tweet['media']  # è¿™å·²ç»æ˜¯æœ¬åœ°ç»å¯¹è·¯å¾„åˆ—è¡¨äº†
    timestamp = tweet['timestamp']
    
    # 1. ç»„è£… B ç«™æ ‡é¢˜: æ ¼å¼ ã‚ã„ã™(Aisu) yyyy-mm-dd hh:mm:ss
    dt_str = datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S")
    target_name = settings.targets.group_name
    settings.publishers.bilibili.title = f"{target_name} {dt_str}"
    
    # 2. ç¿»è¯‘æ­£æ–‡
    logger.info(f"ğŸ§  å¼€å§‹ç¿»è¯‘æ¨æ–‡ {tweet_id} ...")
    translated_text = await translate_text(raw_text)
    
    # æ»¡è¶³è¦æ±‚ä¸€ï¼šæ­£æ–‡æœ«å°¾é™„å¸¦åŸå§‹æ¨æ–‡ ID
    final_content = f"{translated_text}\n\n{tweet_id}"
    
    # 3. è§†é¢‘å‹åˆ¶å¤„ç† (å¦‚æœæœ‰è§†é¢‘çš„è¯)
    video_type = "none"
    final_media_paths = []
    
    for mf in media_files:
        if str(mf).lower().endswith(('.mp4', '.mov')):
            logger.info(f"ğŸ¬ æ£€æµ‹åˆ°è§†é¢‘ï¼Œå¯åŠ¨åª’ä½“ç®¡çº¿...")
            # æ³¨æ„ï¼šä½ çš„ dispatch_media è¿”å›çš„æ˜¯ Noneï¼Œå®ƒæ˜¯ç›´æ¥åœ¨ ready_to_publish é‡Œç”Ÿæˆ final_xxx.mp4
            # è¿™é‡Œæˆ‘ä»¬éœ€è¦æ¨æ–­å‡ºå¤„ç†åçš„è§†é¢‘è·¯å¾„
            source_file = Path(mf)
            PUBLISH_DIR = DATA_DIR / "ready_to_publish"
            output_file = PUBLISH_DIR / f"final_{source_file.name}"
            
            await dispatch_media(str(source_file))
            
            if output_file.exists():
                final_media_paths.append(str(output_file))
                video_type = "translated" if settings.media_engine.enable_ai_translation else "original"
            else:
                final_media_paths.append(str(source_file)) # å…œåº•ç”¨åŸè§†é¢‘
        else:
            final_media_paths.append(mf) # å›¾ç‰‡ç›´æ¥ä¿ç•™
            
    # 4. ç»ˆæå‘å°„
    logger.info("ğŸš€ ç§»äº¤å‘å¸ƒä¸­æ¢...")
    success = await smart_publish(final_content, final_media_paths, video_type=video_type)
    
    # 5. æ¸…ç†å‹åˆ¶äº§ç‰©
    for f in final_media_paths:
        if "ready_to_publish" in str(f):
            try: Path(f).unlink()
            except: pass
            
    return success

async def main_loop():
    logger.info("ğŸ¤– GloBot å·¥ä¸šæµæ°´çº¿å·²å¯åŠ¨...")
    
    # åˆ¤å®šæ˜¯å¦ä¸ºâ€œçœŸÂ·é¦–æ¬¡å¯åŠ¨â€
    is_first_run = not FIRST_RUN_FLAG_FILE.exists()
    
    while True:
        try:
            logger.info("\nğŸ“¡ å¯åŠ¨çˆ¬è™«å—…æ¢...")
            await fetch_timeline()  # æ‰§è¡Œ Playwright åŠ¨ä½œï¼Œè½ç›˜ JSON
            
            json_files = list(RAW_DIR.glob("*.json"))
            if not json_files:
                logger.info("ğŸ’¤ æœªå‘ç° JSON çŸ¿çŸ³ï¼Œä¼‘çœ ä¸­...")
                await asyncio.sleep(60)
                continue
                
            latest_json = max(json_files, key=os.path.getmtime)
            
            # æ‹¿åˆ°ç»“æ„åŒ–çš„æ–°æ¨æ–‡åˆ—è¡¨
            new_tweets = await parse_timeline_json(latest_json)
            
            # é˜…åå³ç„šæ¸…ç† JSON
            try: latest_json.unlink()
            except: pass
            
            if not new_tweets:
                sleep_time = random.randint(240, 420)
                logger.info(f"ğŸ’¤ æ— æ–°åŠ¨æ€ï¼Œä¼‘çœ  {sleep_time} ç§’...")
                await asyncio.sleep(sleep_time)
                continue
                
            # æŒ‰æ—¶é—´ä»æ—§åˆ°æ–°æ’åºï¼Œä¿è¯è¡¥å‘æ—¶é—´è½´æ­£ç¡®
            new_tweets.sort(key=lambda x: x['timestamp'])
            
            # ==========================================
            # ğŸ›¡ï¸ è¦æ±‚äºŒï¼šé¦–æ¬¡å¯åŠ¨æˆªæ–­æœºåˆ¶
            # ==========================================
            if is_first_run:
                logger.warning(f"ğŸš¨ [é¦–å‘ä¿æŠ¤] æ£€æµ‹åˆ°é¦–æ¬¡å¯åŠ¨ï¼Œçˆ¬å–åˆ° {len(new_tweets)} æ¡å†å²æ¨æ–‡ï¼Œä»…ä¿ç•™æœ€æ–°ä¸€æ¡ï¼")
                new_tweets = [new_tweets[-1]]
                # æ ‡è®°é¦–æ¬¡å¯åŠ¨å·²å®Œæˆ
                FIRST_RUN_FLAG_FILE.touch()
                is_first_run = False
            else:
                logger.info(f"ğŸ¯ å¾…å¤„ç†é˜Ÿåˆ—ï¼š{len(new_tweets)} æ¡åŠ¨æ€")

            # ==========================================
            # ğŸ”„ å¤„ç†ä¸å†·å´é˜Ÿåˆ—
            # ==========================================
            total = len(new_tweets)
            for i, tweet in enumerate(new_tweets):
                success = await process_pipeline(tweet)
                if not success:
                    logger.error(f"âŒ æ¨æ–‡ {tweet['id']} å‘å¸ƒå¤±è´¥ï¼Œç½‘ç»œå¼‚å¸¸æˆ–è§¦ç¢°é£æ§ï¼")
                    break # è·³å‡ºå¾ªç¯ï¼Œç­‰ä¸‹ä¸ªå‘¨æœŸå†è¯•ï¼Œé˜²æ­¢ç™½ç»™
                    
                # è¦æ±‚äºŒï¼šé˜Ÿåˆ—ç§¯å‹è¡¥å‘æ—¶ï¼Œå¢åŠ  1 åˆ†é’Ÿå®‰å…¨å†·å´
                if i < total - 1:
                    logger.warning("â³ [é£æ§è§„é¿] è¿ç»­å‘é€å†·å´ä¸­ï¼Œä¼‘çœ  65 ç§’...")
                    await asyncio.sleep(65)
                    
            sleep_time = random.randint(240, 420)
            logger.info(f"âœ… å‘¨æœŸå·¡è§†å®Œæˆï¼Œæ·±åº¦ä¼‘çœ  {sleep_time} ç§’...")
            await asyncio.sleep(sleep_time)
            
        except Exception as e:
            logger.error(f"ğŸ”¥ æ€»çº¿å‘ç”Ÿæœªæ•è·å¼‚å¸¸: {e}")
            await asyncio.sleep(60)

if __name__ == "__main__":
    try:
        asyncio.run(main_loop())
    except KeyboardInterrupt:
        logger.info("\nğŸ›‘ æ”¶åˆ°ç»ˆæ­¢æŒ‡ä»¤ï¼Œå®‰å…¨åœæœºã€‚")